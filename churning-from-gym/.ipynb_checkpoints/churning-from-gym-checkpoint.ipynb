{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Прогнозирование вероятности оттока пользователей для фитнес-центров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\">Работа Юлия Халеевой </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Описание проекта\n",
    "\n",
    "Задача проекта: изучить данные пользователей фитнес-центра и подготовить план действий по удержанию клиентов.\n",
    "Мы планируем:\n",
    "научиться прогнозировать вероятность оттока (на уровне следующего месяца) для каждого клиента;\n",
    "\n",
    "сформировать типичные портреты клиентов: выделить несколько наиболее ярких групп и охарактеризовать их основные свойства;\n",
    "\n",
    "проанализировать основные признаки, наиболее сильно влияющие на отток;\n",
    "\n",
    "сформулировать основные выводы и разработать рекомендации по повышению качества работы с клиентами:\n",
    "1) выделить целевые группы клиентов;\n",
    "\n",
    "2) предложить меры по снижению оттока;\n",
    "\n",
    "3) определить другие особенности взаимодействия с клиентами.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Набор данных включает следующие поля:\n",
    "\n",
    "`Churn` — факт оттока в текущем месяце;\n",
    "\n",
    "Текущие поля в датасете:\n",
    "Данные клиента за предыдущий до проверки факта оттока месяц:\n",
    "\n",
    "`gender` — пол;\n",
    "\n",
    "`Near_Location` — проживание или работа в районе, где находится фитнес-центр;\n",
    "\n",
    "`Partner` — сотрудник компании-партнёра клуба (сотрудничество с компаниями, чьи сотрудники могут получать скидки на абонемент — в таком случае фитнес-центр хранит информацию о работодателе клиента);\n",
    "\n",
    "`Promo_friends` — факт первоначальной записи в рамках акции «приведи друга» (использовал промо-код от знакомого при оплате первого абонемента);\n",
    "\n",
    "`Phone` — наличие контактного телефона;\n",
    "\n",
    "`Age` — возраст;\n",
    "\n",
    "`Lifetime` — время с момента первого обращения в фитнес-центр (в месяцах).\n",
    "\n",
    "Информация на основе журнала посещений, покупок и информация о текущем статусе абонемента клиента:\n",
    "\n",
    "`Contract_period` — длительность текущего действующего абонемента (месяц, 3 месяца, 6 месяцев, год);\n",
    "\n",
    "`Month_to_end_contract` — срок до окончания текущего действующего абонемента (в месяцах);\n",
    "\n",
    "`Group_visits` — факт посещения групповых занятий;\n",
    "\n",
    "`Avg_class_frequency_total` — средняя частота посещений в неделю за все время с начала действия абонемента;\n",
    "\n",
    "`Avg_class_frequency_current_month` — средняя частота посещений в неделю за предыдущий месяц;\n",
    "\n",
    "`Avg_additional_charges_total` — суммарная выручка от других услуг фитнес-центра: кафе, спорт-товары, косметический и массажный салон.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from scipy import stats as st\n",
    "import math as mth\n",
    "import warnings\n",
    "import os\n",
    "from plotly import graph_objects as go\n",
    "import re\n",
    "from io import BytesIO\n",
    "import requests\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.options.display.float_format = \"{:,.2f}\".format\n",
    "pd.set_option(\"max_colwidth\", 120)\n",
    "pd.set_option('display.max_rows', None)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage \n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'gym_churn.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-0e9a2c08510d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#для работы локально\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gym_churn.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    684\u001b[0m     )\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 946\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1176\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2006\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2008\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2009\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'gym_churn.csv'"
     ]
    }
   ],
   "source": [
    "#Загрузим данные\n",
    "#для работы в тренажере\n",
    "\n",
    "if os.path.exists('/datasets/gym_churn.csv'):\n",
    "    df = pd.read_csv('/datasets/gym_churn.csv')\n",
    "\n",
    "#для работы локально\n",
    "else:\n",
    "    df = pd.read_csv('gym_churn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Исследовательский анализ данных (EDA) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'gender': 'Gender'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#проверим, есть ли пропуски\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#проверим, есть ли дубликаты\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наши данные содержат 4000 наблюдений, 13 признаков (объясняющих переменных) и целевую переменную `Churn` -- факт ухода в текущем месяце. Видим, что ни пропусков в данных, ни дубликатов нет.\n",
    "\n",
    "Среди признаков есть 6 категориальных:\n",
    "`gender` — пол;\n",
    "\n",
    "`Near_Location` — проживание или работа в районе, где находится фитнес-центр;\n",
    "\n",
    "`Partner` — сотрудник компании-партнёра клуба (сотрудничество с компаниями, чьи сотрудники могут получать скидки на абонемент — в таком случае фитнес-центр хранит информацию о работодателе клиента);\n",
    "\n",
    "`Promo_friends` — факт первоначальной записи в рамках акции «приведи друга» (использовал промо-код от знакомого при оплате первого абонемента);\n",
    "\n",
    "`Phone` — наличие контактного телефона;\n",
    "\n",
    "`Group_visits` — факт посещения групповых занятий.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраним копию файла\n",
    "df_initial = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на социальный портрет пользователя.\n",
    "    \n",
    "Это с равной вероятностью мужчина или женщина,\n",
    "    \n",
    "30 лет,\n",
    "    \n",
    "живет близко от фитнес-клуба,\n",
    "    \n",
    "оформляет абонемент на 5 месяцев,\n",
    "    \n",
    "в трети случаев приходит по промокоду,\n",
    "    \n",
    "в четверти случаев покидает клуб."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_plot(data, column):\n",
    "    '''Функция строит гистограмму для конкретной переменной\n",
    "    '''\n",
    "    plt.figure(figsize=(13,7))\n",
    "    sns.set_style(\"whitegrid\") \n",
    "    sns.displot(data, x=column, hue=\"Churn\", alpha=0.5, height = 6, aspect = 10/6)\n",
    "    plt.legend(['да', 'нет'], title = 'Отток', loc = 'best')\n",
    "    plt.title(f'Распределение признака {column}', fontsize=15)\n",
    "    plt.xlabel('Признак', fontsize=12)\n",
    "    plt.ylabel('Частота', fontsize=12)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = df.drop(['Churn'], axis = 1).columns\n",
    "feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for feature  in feature_list: \n",
    "    hist_plot(df, feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Особенных выбросов мы не наблюдаем. Наши категориальные переменные уже имеют вид дамми-переменных, так что не требуют дополнительного преобразования."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что \n",
    "    \n",
    "по полу различий практически нет\n",
    "\n",
    "живущих близко в выборке гораздо больше и доля \"утекающих\" среди них меньше\n",
    "    \n",
    "среди тех, кто работает в компании-партнере, отток ниже\n",
    "    \n",
    "тех, кто пришел по промокоду, меньше, но и отток среди них меньше\n",
    "\n",
    "абонемент бывает на 1 месяц, на 6 месяцев и на год, среди тех, кто покупает абонемент на месяц, отток самый большой, среди тех, кто на год, самый маленький\n",
    "    \n",
    "более молодые уходят чаще\n",
    "    \n",
    "те, кто ходит реже и меньше тратит на дополнительные услуги, уходит чаще."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#построим матрицу корреляций\n",
    "df_corr = df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "sns.set(style='white')\n",
    "plt.title('Матрица корреляций')\n",
    "sns.heatmap(df_corr, annot=True, fmt='.1%', linewidths=1, linecolor='white')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что имеются мультиколлинеарность, обнаруживаются две пары сильно коррелированных признаков:\n",
    "\n",
    "`Avg_class_frequency_total` \n",
    "\n",
    "`Avg_class_frequency_current_month`    \n",
    "\n",
    "и\n",
    "\n",
    "`Month_to_end_contract`\n",
    "\n",
    "`Contract_period`\n",
    "\n",
    "Исключим по одному признаку из каждой пары, оставим\n",
    "`Avg_class_frequency_total` \n",
    "и\n",
    "`Contract_period`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Month_to_end_contract', 'Avg_class_frequency_current_month'], axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Построение модели прогнозирования оттока клиентов\n",
    "Постройте модель бинарной классификации клиентов, где целевой признак — факт оттока клиента в следующем месяце:\n",
    "\n",
    "Разбейте данные на обучающую и валидационную выборку функцией train_test_split().\n",
    "\n",
    "Обучите модель на train-выборке двумя способами:\n",
    "\n",
    "логистической регрессией,\n",
    "\n",
    "случайным лесом.\n",
    "\n",
    "Оцените метрики accuracy, precision и recall для обеих моделей на валидационной выборке. \n",
    "\n",
    "Сравните по ним модели. Какая модель показала себя лучше на основании метрик?\n",
    "\n",
    "Не забудьте указать параметр random_state при разделении выборки и задании алгоритма.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Разобьем данные на обучающую и валидационную выборку функцией train_test_split().\n",
    "X = df.drop('Churn', axis = 1) \n",
    "y = df['Churn'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# определим функцию, которая будет выводить метрики\n",
    "def print_all_metrics(y_true, y_pred, y_proba, title='Метрики классификации'):\n",
    "    print(title)\n",
    "    print('\\tAccuracy: {:.2f}'.format(accuracy_score(y_true, y_pred)))\n",
    "    print('\\tPrecision: {:.2f}'.format(precision_score(y_true, y_pred)))\n",
    "    print('\\tRecall: {:.2f}'.format(recall_score(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# обучим StandardScaler на обучающей выборке\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    " \n",
    "# Преобразуем обучающий и валидационные наборы данных\n",
    "X_train_st = scaler.transform(X_train)\n",
    "X_test_st = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель с помощью логистической регрессии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# зададим алгоритм для модели логистической регрессии\n",
    "lr_model = LogisticRegression(solver='liblinear', random_state=0)\n",
    "\n",
    "# обучим модель\n",
    "lr_model.fit(X_train_st, y_train)\n",
    "\n",
    "# воспользуемся уже обученной моделью, чтобы сделать прогнозы\n",
    "lr_predictions = lr_model.predict(X_test_st)\n",
    "lr_probabilities = lr_model.predict_proba(X_test_st)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# выведем все метрики\n",
    "print_all_metrics(\n",
    "    y_test,\n",
    "    lr_predictions,\n",
    "    lr_probabilities,\n",
    "    title='Метрики для модели логистической регрессии:',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь обучим модель с помощью случайного леса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# зададим алгоритм для нашей модели на основе алгоритма случайного леса\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# зададим алгоритм для новой модели на основе алгоритма случайного леса\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=0) \n",
    "# обучим модель случайного леса\n",
    "rf_model.fit(X_train, y_train)\n",
    "# воспользуемся уже обученной моделью, чтобы сделать прогнозы\n",
    "rf_predictions =  rf_model.predict(X_test) # Ваш код здесь\n",
    "rf_probabilities = rf_model.predict_proba(X_test)[:,1] # Ваш код здесь\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# выведем все метрики\n",
    "print_all_metrics(\n",
    "    y_test, \n",
    "    rf_predictions,\n",
    "    rf_probabilities,\n",
    "    title = 'Метрики для модели случайного леса:'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что логистическая регрессия на стандартизованных данных дает лучшие результаты, чем случайный лес (лучшие в смысле метрик accuracy, precision и recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Кластеризация\n",
    "Сделайте кластеризацию клиентов\n",
    "\n",
    "Отложите в сторону столбец с оттоком и проведите кластеризацию объектов (клиентов):\n",
    "\n",
    "Стандартизируйте данные.\n",
    "\n",
    "Постройте матрицу расстояний функцией linkage() на стандартизованной матрице признаков и нарисуйте дендрограмму. \n",
    "Внимание: отрисовка дендрограммы может занять время! На основании полученного графика предположите, какое количество кластеров можно выделить.\n",
    "\n",
    "Обучите модель кластеризации на основании алгоритма K-Means и спрогнозируйте кластеры клиентов. Договоримся за число кластеров принять n=5, чтобы ваши результаты можно было сравнивать с результатами остальных студентов. Однако, конечно, в жизни никто не скажет вам правильный ответ, и решение остаётся за вами (на основании изучения графика из предыдущего пункта).\n",
    "\n",
    "Посмотрите на средние значения признаков для кластеров. Можно ли сразу что-то заметить?\n",
    "\n",
    "Постройте распределения признаков для кластеров. Можно ли что-то заметить по ним?\n",
    "\n",
    "Для каждого полученного кластера посчитайте долю оттока (методом groupby()). Отличаются ли они по доле оттока? Какие кластеры склонны к оттоку, а какие — надёжны?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# обучим StandardScaler на всей выборке\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    " \n",
    "# Преобразуем все данные\n",
    "X_st = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#построим таблицу связок между объектами\n",
    "linked = linkage(X_st, method = 'ward') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#построим дендрограмму (no_labels = True, чтобы дендрограмма строилась быстрее)\n",
    "plt.figure(figsize=(15, 10))  \n",
    "dendrogram(linked, orientation='top', no_labels = True)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дендрограмма демонстрирует, что данные разумно разделить на 4 кластера.\n",
    "\n",
    "Следуя заданию, разделим их на 5 кластеров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# определим функцию для построения графиков попарных признаков для кластеров\n",
    "def show_clusters_on_plot(df, x_name, y_name, cluster_name):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    sns.scatterplot(\n",
    "        df[x_name], df[y_name], hue=df[cluster_name], palette='Paired'\n",
    "    )\n",
    "    plt.title('{} vs {}'.format(x_name, y_name))\n",
    "    plt.show()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# зададим модель k_means с числом кластеров 5\n",
    "km = KMeans(n_clusters = 5, random_state = 0)\n",
    "# спрогнозируем кластеры для наблюдений (алгоритм присваивает им номера от 0 до 4)\n",
    "labels = km.fit_predict(X_st)\n",
    " \n",
    "# сохраним метки кластера в поле нашего датасета\n",
    "df['cluster'] = labels\n",
    " \n",
    "# выведем статистику по средним значениям наших признаков по кластеру\n",
    "df.groupby('cluster').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что кластеры отличаются по доле оттока. \n",
    "\n",
    "Самый надежный кластер 2, оттуда практически никто не уходит (отток = 0,02). Это люди, которые живут рядом, пришли давно и не по промокоду, чаще других ходят на групповые занятия и вообще в клуб, больше денег тратят на сопутствующие услуги в клубе.\n",
    "\n",
    "Следующий по надежности кластер 1 (отток = 0,12). Это люди, работающие в компании-партнере, они тоже чаще других ходят на групповые занятия и вообще в клуб и больше денег тратят на сопутствующие услуги в клубе (но меньше, чем кластер 2).\n",
    "\n",
    "Самый ненадежный кластер 3 (отток = 0,55). Это люди, пришедшие недавно, у них самый короткий срок, на который оформлен абонемент. Они реже прочих ходят на групповые занятия и меньше денег тратят на сопутствующие услуги в клубе. Они чуть моложе остальных и чаще относятся к полу , обозначенному 1.\n",
    "\n",
    "Кластер 0 тоже достаточно ненадежен (отток = 0,4). Этот кластер отличается от других тем, что люди тут не живут рядом с клубом.\n",
    "\n",
    "Кластер 4 -- люди, которые не оставили свой телефон, на удивление не отличаются чрезмерной ненадежностью, их резултат равен среднему (0,27).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим графики распределения переменных по кластерам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#если бы мы хотели разделить выборку на кластеры, можно было бы сделать это так\n",
    "# for i in range(4):\n",
    "#     df_i = df.query('cluster==@i')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countplot_by_clusters(data, column):\n",
    "    #Функция строит распределение для конкретной дискретной переменной по кластерам\n",
    "    \n",
    "    plt.figure(figsize=(13,7))\n",
    "    sns.set_style(\"whitegrid\") \n",
    "    sns.countplot(data=data, x=column, hue = 'cluster')\n",
    "    plt.title(f'Распределение {column}', fontsize=15)\n",
    "    plt.xlabel('Признак', fontsize=12)\n",
    "    plt.ylabel('Частота', fontsize=12)\n",
    "    plt.legend(title = 'Кластер')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxplot(data, column):\n",
    "    #Функция строит распределение для конкретной непрерывной переменной\n",
    "    \n",
    "    plt.figure(figsize=(13,7))\n",
    "    sns.set_style(\"whitegrid\") \n",
    "    sns.boxplot(data = data, x = column)\n",
    "    plt.title(f'Распределение {column} в кластере {i}', fontsize=15)\n",
    "    plt.xlabel('Признак', fontsize=12)\n",
    "    plt.ylabel('Частота', fontsize=12)\n",
    "    plt.legend('')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discreet_feature_list = df.columns.drop(['Avg_additional_charges_total', \n",
    "                    'Lifetime', 'Avg_class_frequency_total', 'Age' ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continous_feature_list = ['Avg_additional_charges_total', \n",
    "                    'Lifetime', 'Avg_class_frequency_total', 'Age' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature  in discreet_feature_list: \n",
    "    countplot_by_clusters(df, feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature  in continous_feature_list: \n",
    "    for i in range(4):\n",
    "        boxplot(df.loc[df['cluster']==i], feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы построили распределения признаков отдельно по кластерам.\n",
    "\n",
    "Запишем некоторые наблюдения:\n",
    "    \n",
    "далеко от клуба живут только персонажи из кластера 0 и некоторые из кластера 4, все остальные живут близко\n",
    "\n",
    "во всех кластерах есть те, кто работает на предприятии-партнере, но в кластере 1 их существенно больше\n",
    "\n",
    "по промокоду приходят представители всех кластеров, но в кластере 1 их опять существенно больше\n",
    "\n",
    "телефон не оставляют только персонажи из кластера 4\n",
    "\n",
    "абонемент на 1 месяц покупают персонажи из всех кластеров, но в 3 кластере таких существенно больше.\n",
    "\n",
    "На последних графиках из первой серии мы можем сравнить размер кластеров, видим, что 1 и 3 самые большие, а 4 самый маленький.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы и базовые рекомендации по работе с клиентами "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы видим, что некоторые характеристики коррелированы с тем, что клиент менее вероятно стремится покинуть наш клуб. \n",
    "Мы не можем уверенно говорить о причинно-следственной связи, но тем не менее кажется осмысленным обратить внимание на клиентов из этих групп.\n",
    "\n",
    "Сюда относятся \n",
    "\n",
    "те, кто пришли по промокоду\n",
    "\n",
    "те, кто работает в компании-партнере\n",
    "\n",
    "те, кто часто ходит на групповые занятия и просто в клуб\n",
    "\n",
    "те, кто больше денег тратит на сопутствующие услуги в клубе.\n",
    "\n",
    "Также более надежными являются более старые клиенты и те, кто покупает более длинные абонементы (здесь особенно вероятна обратная причинно-следственная связь: тот, кому нравится и подходит клуб, не планирует его покидать и покупает длинный абонемент).\n",
    "\n",
    "Рекомендуемые маркетинговые действия: \n",
    "\n",
    "1. Следить за клиентами из этих групп, удостоверяясь, что они довольны. При недовольстве стараться удержать клиентов, предлагая какие-то поощрительные меры (например, бесплатные тренировки из тех).\n",
    "\n",
    "2. Те, кто живут далеко, не являются особенно надежными клиентами, так что, видимо, нам не имеет особенного смысла вешать рекламу далеко от клуба, а стоит сосредоточиться на нашем районе.\n",
    "\n",
    "3. Политика раздачи промокодов себя оправдывает, так что ее стоит продолжать, но именно в том виде и по тем каналам, по которым они распространябтся сейчас, нельзя быть уверенным, что новый канал приведет к нам таких же надежных клиентов.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 2212,
    "start_time": "2021-07-10T01:05:37.371Z"
   },
   {
    "duration": 24,
    "start_time": "2021-07-10T01:05:39.586Z"
   },
   {
    "duration": 19,
    "start_time": "2021-07-10T01:05:39.613Z"
   },
   {
    "duration": 21,
    "start_time": "2021-07-10T01:05:39.635Z"
   },
   {
    "duration": 11,
    "start_time": "2021-07-10T01:05:39.658Z"
   },
   {
    "duration": 13,
    "start_time": "2021-07-10T01:05:39.671Z"
   },
   {
    "duration": 15,
    "start_time": "2021-07-10T01:05:39.687Z"
   },
   {
    "duration": 4,
    "start_time": "2021-07-10T01:05:39.704Z"
   },
   {
    "duration": 44,
    "start_time": "2021-07-10T01:05:39.713Z"
   },
   {
    "duration": 65,
    "start_time": "2021-07-10T01:05:39.761Z"
   },
   {
    "duration": 6,
    "start_time": "2021-07-10T01:05:39.828Z"
   },
   {
    "duration": 27,
    "start_time": "2021-07-10T01:05:39.836Z"
   },
   {
    "duration": 755,
    "start_time": "2021-07-10T01:05:39.867Z"
   },
   {
    "duration": 188,
    "start_time": "2021-07-10T01:05:40.436Z"
   },
   {
    "duration": 188,
    "start_time": "2021-07-10T01:05:40.438Z"
   },
   {
    "duration": 187,
    "start_time": "2021-07-10T01:05:40.440Z"
   },
   {
    "duration": 185,
    "start_time": "2021-07-10T01:05:40.443Z"
   },
   {
    "duration": 183,
    "start_time": "2021-07-10T01:05:40.447Z"
   },
   {
    "duration": 181,
    "start_time": "2021-07-10T01:05:40.450Z"
   },
   {
    "duration": 180,
    "start_time": "2021-07-10T01:05:40.452Z"
   },
   {
    "duration": 179,
    "start_time": "2021-07-10T01:05:40.454Z"
   },
   {
    "duration": 178,
    "start_time": "2021-07-10T01:05:40.456Z"
   },
   {
    "duration": 178,
    "start_time": "2021-07-10T01:05:40.458Z"
   },
   {
    "duration": 177,
    "start_time": "2021-07-10T01:05:40.460Z"
   },
   {
    "duration": 176,
    "start_time": "2021-07-10T01:05:40.462Z"
   },
   {
    "duration": 175,
    "start_time": "2021-07-10T01:05:40.464Z"
   },
   {
    "duration": 174,
    "start_time": "2021-07-10T01:05:40.467Z"
   },
   {
    "duration": 172,
    "start_time": "2021-07-10T01:05:40.470Z"
   },
   {
    "duration": 171,
    "start_time": "2021-07-10T01:05:40.472Z"
   },
   {
    "duration": 169,
    "start_time": "2021-07-10T01:05:40.475Z"
   },
   {
    "duration": 166,
    "start_time": "2021-07-10T01:05:40.480Z"
   },
   {
    "duration": 5396,
    "start_time": "2021-07-10T01:06:55.637Z"
   },
   {
    "duration": 4190,
    "start_time": "2021-07-10T01:07:07.385Z"
   },
   {
    "duration": 2328,
    "start_time": "2021-07-10T01:07:11.578Z"
   },
   {
    "duration": 24,
    "start_time": "2021-07-10T01:07:13.909Z"
   },
   {
    "duration": 23,
    "start_time": "2021-07-10T01:07:13.935Z"
   },
   {
    "duration": 6,
    "start_time": "2021-07-10T01:07:13.961Z"
   },
   {
    "duration": 16,
    "start_time": "2021-07-10T01:07:13.970Z"
   },
   {
    "duration": 7,
    "start_time": "2021-07-10T01:07:13.988Z"
   },
   {
    "duration": 11,
    "start_time": "2021-07-10T01:07:13.999Z"
   },
   {
    "duration": 45,
    "start_time": "2021-07-10T01:07:14.013Z"
   },
   {
    "duration": 5,
    "start_time": "2021-07-10T01:07:14.062Z"
   },
   {
    "duration": 91,
    "start_time": "2021-07-10T01:07:14.070Z"
   },
   {
    "duration": 10,
    "start_time": "2021-07-10T01:07:14.165Z"
   },
   {
    "duration": 10,
    "start_time": "2021-07-10T01:07:14.178Z"
   },
   {
    "duration": 19939,
    "start_time": "2021-07-10T01:07:14.190Z"
   },
   {
    "duration": 6,
    "start_time": "2021-07-10T01:07:34.132Z"
   },
   {
    "duration": 2125,
    "start_time": "2021-07-10T01:07:34.140Z"
   },
   {
    "duration": 5,
    "start_time": "2021-07-10T01:07:36.268Z"
   },
   {
    "duration": 29,
    "start_time": "2021-07-10T01:07:36.276Z"
   },
   {
    "duration": 12,
    "start_time": "2021-07-10T01:07:36.307Z"
   },
   {
    "duration": 12,
    "start_time": "2021-07-10T01:07:36.321Z"
   },
   {
    "duration": 19,
    "start_time": "2021-07-10T01:07:36.336Z"
   },
   {
    "duration": 18,
    "start_time": "2021-07-10T01:07:36.359Z"
   },
   {
    "duration": 18,
    "start_time": "2021-07-10T01:07:36.382Z"
   },
   {
    "duration": 12,
    "start_time": "2021-07-10T01:07:36.402Z"
   },
   {
    "duration": 4,
    "start_time": "2021-07-10T01:07:36.416Z"
   },
   {
    "duration": 523,
    "start_time": "2021-07-10T01:07:36.422Z"
   },
   {
    "duration": 17,
    "start_time": "2021-07-10T01:07:36.947Z"
   },
   {
    "duration": 11,
    "start_time": "2021-07-10T01:07:36.967Z"
   },
   {
    "duration": 811,
    "start_time": "2021-07-10T01:07:36.981Z"
   },
   {
    "duration": 873,
    "start_time": "2021-07-10T01:07:37.795Z"
   },
   {
    "duration": 5,
    "start_time": "2021-07-10T01:07:38.672Z"
   },
   {
    "duration": 1484,
    "start_time": "2021-07-10T01:07:38.680Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
